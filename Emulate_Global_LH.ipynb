{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd83631-73ea-41da-8f3f-e5f1913ad981",
   "metadata": {},
   "source": [
    "# FATES SP LH analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddf99d-4d18-4a59-9051-482c56c334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import gpflow\n",
    "\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "from esem import gp_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "from SALib.sample import fast_sampler\n",
    "from SALib.analyze import fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8df00-e2bd-4536-b7de-b5da7f95cad2",
   "metadata": {},
   "source": [
    "## PBS Cluster Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fdfb2-6374-491d-8fff-dd6817a14c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PBSCluster\n",
    "cluster = PBSCluster(\n",
    "    cores=1,                                     # The number of cores you want\n",
    "    memory='25GB',                               # Amount of memory\n",
    "    processes=1,                                 # How many processes\n",
    "    queue='casper',                              # The type of queue to utilize\n",
    "    local_directory='/glade/work/afoster',       # Use your local directory\n",
    "    resource_spec='select=1:ncpus=1:mem=25GB',   # Specify resources\n",
    "    project='P93300041',                         # Input your project ID here\n",
    "    walltime='04:00:00',                         # Amount of wall time\n",
    "    interface='ext',                             # Interface to use\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035473b-21bd-4b28-809e-8ef257041f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d20148-4a82-4d00-aa32-2338e24774e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb397d-152e-48a2-ab2c-38a794ed3216",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4be653-4085-43f6-a580-e51a57257592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(files, whittaker_ds):\n",
    "\n",
    "    # read in dataset and attach other info\n",
    "    ds = xr.open_mfdataset(files, combine='nested', concat_dim='ensemble',\n",
    "                           parallel=True, chunks = {'time': 60, 'ensemble': 100,\n",
    "                                                    'gridcell': 200})\n",
    "\n",
    "    ds['biome'] = whittaker_ds.biome\n",
    "    ds['biome_name'] = whittaker_ds.biome_name\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fd54f-34a0-4b27-869d-4fa065e71cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_mean(da):\n",
    "\n",
    "    cf1, cf2 = cfs[da.name].values()\n",
    "\n",
    "    days_per_month = da['time.daysinmonth']\n",
    "    ann_mean = cf1*(days_per_month*da).groupby('time.year').sum()\n",
    "    ann_mean.name = da.name\n",
    "    return ann_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6faf10e-b649-4724-8f5e-d14e828428d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_wts(nyears):\n",
    "\n",
    "    days_pm = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "    return xr.DataArray(np.tile(days_pm, nyears), dims='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9acdd9-87f7-47af-956d-c703ead113c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_mean(ds, data_var, domain, cfs, land_area):\n",
    "    '''\n",
    "    Calculate area mean for data_var across gridcells, either globally or by biome\n",
    "    ds:        dataset\n",
    "    data_var:  data variable\n",
    "    domain:   'global' or 'biome'\n",
    "    cfs:       unit conversion factors\n",
    "    land_area: land area dataset\n",
    "    '''\n",
    "\n",
    "    # update conversion factor if need be\n",
    "    cf1, cf2 = cfs[data_var].values()\n",
    "    if cf2 == 'intrinsic':\n",
    "        if domain == 'global':\n",
    "            cf2 = 1/land_area.sum()\n",
    "        else:\n",
    "            cf2 = 1/land_area.groupby(ds.biome).sum()\n",
    "\n",
    "    # weight by landarea\n",
    "    area_weighted = land_area*ds[data_var]\n",
    "\n",
    "    # sort out domain groupings\n",
    "    area_weighted['biome'] = ds.biome\n",
    "    area_weighted = area_weighted.swap_dims({'gridcell': 'biome'})\n",
    "    if domain == 'global':\n",
    "        # every gridcell is in biome 1\n",
    "        grid = 1+0*area_weighted.biome\n",
    "    else:\n",
    "        grid = area_weighted.biome\n",
    "\n",
    "    # calculate area mean\n",
    "    area_mean = cf2*area_weighted.groupby(grid).sum()\n",
    "\n",
    "    if domain == 'global':\n",
    "        # get rid of gridcell dimension\n",
    "        area_mean = area_mean.mean(dim='biome')\n",
    "\n",
    "    area_mean.name = data_var\n",
    "\n",
    "    return area_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfa433-c912-41e7-ae0d-e25d0b6c12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(ds, da):\n",
    "    \n",
    "    thedir = '/glade/u/home/forrest/ppe_representativeness/output_v4/'\n",
    "    thefile = 'clusters.clm51_PPEn02ctsm51d021_2deg_GSWP3V1_leafbiomassesai_PPE3_hist.annual+sd.400.nc'\n",
    "    sg = xr.open_dataset(thedir + thefile)\n",
    "\n",
    "    out = np.zeros(sg.cclass.shape) + np.nan\n",
    "    for c, (o, a) in enumerate(sg.rcent_coords):\n",
    "        i = np.arange(400)[\n",
    "            (abs(ds.grid1d_lat - a) < 0.1) &\n",
    "            (abs(ds.grid1d_lon - o) < 0.1)]\n",
    "        out[sg.cclass == c + 1] = i\n",
    "    cclass = out.copy()\n",
    "    cclass[np.isnan(out)] = 0\n",
    "\n",
    "    sgmap = xr.Dataset()\n",
    "    sgmap['cclass'] = xr.DataArray(cclass.astype(int), dims=['lat', 'lon'])\n",
    "    sgmap['notnan'] = xr.DataArray(~np.isnan(out), dims=['lat', 'lon'])\n",
    "    sgmap['lat'] = sg.lat\n",
    "    sgmap['lon'] = sg.lon\n",
    "    \n",
    "    damap = da.sel(gridcell=sgmap.cclass).where(sgmap.notnan).compute()\n",
    "    \n",
    "    return damap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfae9b5-d03c-4135-b319-eb97d8f5cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(var):\n",
    "    return (var - min(var))/(max(var) - min(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb1a65-f87b-48a6-b870-18a8f50fcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(norm_var, raw_var):\n",
    "    return norm_var*np.array(max(raw_var) - min(raw_var)) + np.array(min(raw_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8ce90-eb8d-40ca-ba35-3ae4c67b4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(var, params, n_test):\n",
    "\n",
    "    # target variable (excluding default [0])\n",
    "    Y = var[1:].values\n",
    "\n",
    "    # test and training parameters\n",
    "    X_test, X_train = params[:n_test], params[n_test:]\n",
    "\n",
    "    # test and training output\n",
    "    y_test, y_train = Y[:n_test], Y[n_test:]\n",
    "\n",
    "    return X_test, X_train, y_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd8952-8098-4dce-9c02-82f7379630be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_emulator(num_params, X_train, y_train):\n",
    "\n",
    "    # create kernel\n",
    "    kernel_linear = gpflow.kernels.Linear(active_dims=range(num_params),\n",
    "                                          variance=1)\n",
    "    kernel_matern32 = gpflow.kernels.Matern32(active_dims=range(num_params),\n",
    "                                              variance=1,\n",
    "                                              lengthscales=np.tile(1, num_params))\n",
    "    kernel = kernel_linear + kernel_matern32\n",
    "\n",
    "    # define emulator model and train\n",
    "    emulator = gp_model(np.array(X_train), np.array(y_train), kernel=kernel)\n",
    "    emulator.train()\n",
    "\n",
    "    return emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb093d78-5418-4249-9c4b-59fb4093113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_sensitivity(emulator):\n",
    "\n",
    "    # fourier amplitude sensitivity test w/emulator\n",
    "    problem = {\n",
    "        'names': ppe_params.columns,\n",
    "        'num_vars': num_params,\n",
    "        'bounds': [[0, 1]],\n",
    "    }\n",
    "\n",
    "    sample = fast_sampler.sample(problem, 1000, M=4, seed=None)\n",
    "    Y, _ = emulator.predict(sample)\n",
    "    FAST = fast.analyze(problem, Y, M=4, num_resamples=100, conf_level=0.95,\n",
    "                        print_to_console=False, seed=None)\n",
    "    sens = pd.DataFrame.from_dict(FAST)\n",
    "    sens.index = sens.names\n",
    "    df_sens = sens.sort_values(by=['S1'], ascending=False)\n",
    "\n",
    "    return df_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf474d72-3ba5-422d-9931-9319e2e2672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oaat_sens(ppe_params, emulator, default):\n",
    "\n",
    "    num_params = len(ppe_params.columns)\n",
    "\n",
    "    # hold all parameters at median value\n",
    "    n = 21\n",
    "    unif = pd.concat([pd.DataFrame(np.tile(0.5, n))]*num_params, axis=1)\n",
    "    unif.columns = ppe_params.columns\n",
    "    s = np.linspace(0, 1, n)\n",
    "\n",
    "    sample = unif\n",
    "    plt.figure(figsize=[18, 16])\n",
    "    for i, p in enumerate(ppe_params.columns):\n",
    "        sample[p] = s\n",
    "        oaat, v = emulator.predict(sample.values)\n",
    "        sample[p] = np.tile(0.5, n)  # set column back to median\n",
    "\n",
    "        ax = plt.subplot(7, 5, i + 1)\n",
    "        ax.fill_between(s, oaat - 3.0*v**0.5, oaat + 3.0*v**0.5, color='peru',\n",
    "                        alpha=0.4)  # shade three standard deviations\n",
    "        ax.plot(s, oaat, c='k')\n",
    "        ax.set_xlabel(p)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06b570-4233-426a-8a2b-16ddcf7ce52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lon(ds, lon_name):\n",
    "\n",
    "    # Adjust lon values to make sure they are within (-180, 180)\n",
    "    ds['_longitude_adjusted'] = xr.where(\n",
    "        ds[lon_name] > 180,\n",
    "        ds[lon_name] - 360,\n",
    "        ds[lon_name])\n",
    "\n",
    "    # reassign the new coords to as the main lon coords\n",
    "    # and sort DataArray using new coordinate values\n",
    "    ds = (\n",
    "        ds\n",
    "        .swap_dims({lon_name: '_longitude_adjusted'})\n",
    "        .sel(**{'_longitude_adjusted': sorted(ds._longitude_adjusted)})\n",
    "        .drop_vars(lon_name))\n",
    "\n",
    "    ds = ds.rename({'_longitude_adjusted': lon_name})\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d9add-0d44-458b-b41a-609b9729600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ooat_sens(ppe_params, emulator, dir, var):\n",
    "    num_params = len(ppe_params.columns)\n",
    "\n",
    "    # hold all parameters at median value\n",
    "    n = 50\n",
    "    unif = pd.concat([pd.DataFrame(np.tile(0.5, n))]*num_params, axis=1)\n",
    "    unif.columns = ppe_params.columns\n",
    "    s = np.linspace(0, 1, n)\n",
    "    param = np.array([])\n",
    "    oaats = np.array([])\n",
    "    vars = np.array([])\n",
    "    samps = np.array([])\n",
    "    sample = unif\n",
    "    for i, p in enumerate(ppe_params.columns):\n",
    "        sample[p] = s\n",
    "        oaat, v = emulator.predict(sample.values)\n",
    "        sample[p] = np.tile(0.5, n)  # set column back to median\n",
    "        oaats = np.append(oaats, oaat)\n",
    "        vars = np.append(vars, v)\n",
    "        param = np.append(param, np.repeat(p, n))\n",
    "        samps = np.append(samps, s)\n",
    "    df = {'sample': samps,\n",
    "      'predict': oaats,\n",
    "      'variance': vars,\n",
    "      'parameter': param}\n",
    "    dataf = pd.DataFrame(df)\n",
    "    dataf.to_csv(f'{dir}/{var}_oaat_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5bbd3-ebea-4887-8624-dd00fbb35a61",
   "metadata": {},
   "source": [
    "## Directory Names and Conversion Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c9be6-31de-4068-8712-0b9653514c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the sparsegrid landarea - needed for unit conversion\n",
    "land_area_file = '/glade/work/afoster/FATES_calibration/CLM5PPE/postp/sparsegrid_landarea.nc'\n",
    "land_area_dat = xr.open_dataset(land_area_file)\n",
    "land_area = land_area_dat.landarea  # km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717f93f-8ac5-4194-b1e8-5c816f24ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whittaker biomes\n",
    "whit = xr.open_dataset('/glade/work/afoster/FATES_calibration/CLM5PPE/pyth/whit/whitkey.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a40a3-d21c-45f3-8ef7-dc6467288750",
   "metadata": {},
   "outputs": [],
   "source": [
    "topdir = '/glade/work/afoster/FATES_calibration/FATES_SP_LH/hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83236c23-df10-42f4-895e-9815de668fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion factors\n",
    "cfs = {'GPP': {'cf1': 24*60*60, 'cf2': 1e-6},\n",
    "       'EFLX_LH_TOT': {'cf1': 1/2.5e6*24*60*60, 'cf2': 1e-9},\n",
    "       'ASA': {'cf1': 1/365, 'cf2': 'intrinsic'},\n",
    "       'SOILWATER_10CM': {'cf1': 1/365, 'cf2': 1e-9},\n",
    "       'FSH': {'cf1': 1/365, 'cf2': 'intrinsic'},\n",
    "       'Temp': {'cf1': 1/365, 'cf2': 'intrinsic'}}\n",
    "units = {'GPP': 'PgC/yr',\n",
    "         'EFLX_LH_TOT': 'TtH2O/yr',\n",
    "         'ASA': '0-1',\n",
    "         'SOILWATER_10CM': 'TtH2O',\n",
    "         'FSH': 'W/m2',\n",
    "         'Temp': 'degrees C'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813e710-9e8e-41e8-9ce5-5552978bcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_obs = xr.open_dataset('ILAMB_global_obs.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7d031-4749-4c74-9a9d-03d81dc72ef4",
   "metadata": {},
   "source": [
    "## Read in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ec7ee-4b91-4f04-8ee2-cf1c1b06f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted([os.path.join(topdir, file) for file in os.listdir(topdir)])\n",
    "ds = get_ensemble(files, whit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f8eeb-08d5-4e77-bdb4-5a12e5e24290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lhckey = '/glade/u/home/afoster/CLM_PPE_FATES/FATES_SP_Calib/lh_key.csv'\n",
    "lhckey = '/glade/work/afoster/FATES_calibration/FATES_SP_LH/lh_key_300.csv'\n",
    "df = pd.read_csv(lhckey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84410447-ea21-4612-94dd-a88a9c3f36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppe_params = df #z.drop(columns=['ensemble'])\n",
    "num_params = len(ppe_params.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21c1f4-18f1-4bb3-9879-086918a07cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e901ea-d4c3-45bc-9056-e6c20ee7a315",
   "metadata": {},
   "source": [
    "## Global Annual GPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5eb19-7842-453c-bb2d-4429d53d4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global annual mean (PgC/yr)\n",
    "gpp_glob = annual_mean(area_mean(ds, 'GPP', 'global', cfs, land_area)).mean(dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be84c1-424d-42e7-8576-3512f8f36d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training/testing\n",
    "params_test, params_train, gpp_test, gpp_train = split_dataset(gpp_glob, ppe_params, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec304bdb-a6e9-4d6f-897c-80318ba123b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train emulator\n",
    "gpp_em = train_emulator(num_params, params_train, gpp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876893fe-3f3e-480f-907a-25a2f387ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test points with emulator\n",
    "gpp_pred, gpp_pred_var = gpp_em.predict(params_test)\n",
    "st_dev = gpp_pred_var.flatten()**0.5\n",
    "rms = mean_squared_error(gpp_test, gpp_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0de183-dfc9-4f73-b8cb-d58fdd1453c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'gpp_test': gpp_test,\n",
    "     'gpp_pred': gpp_pred,\n",
    "     'gpp_var': gpp_pred_var}\n",
    "gpp_test_pred = pd.DataFrame(df)\n",
    "gpp_test_pred.to_csv('LH_output_global/gpp_test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bc42e-2cd9-4f91-9ae0-e72c3f3334c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpp_sens = fourier_sensitivity(gpp_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab4edd-7f5f-43bb-baba-c3086d6dcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpp_sens.to_csv('LH_output_global/gpp_sensitivity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f11ef-d3fb-4a12-b6af-cd865ba6d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oaat_sens(ppe_params, gpp_em, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308e011-0e4c-4328-8b77-fd3d31ec29bf",
   "metadata": {},
   "source": [
    "## Global Annual Evapotranspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbca47c-ae4b-43e2-b33f-b11cc1bdacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global annual mean (TtH2O/yr)\n",
    "et_glob = annual_mean(area_mean(ds, 'EFLX_LH_TOT', 'global', cfs, land_area)).mean(dim='year')\n",
    "\n",
    "# default et\n",
    "#default_et = et_glob[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b4d5a-38ee-4904-8758-200429966d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training/testing\n",
    "params_test, params_train, et_test, et_train = split_dataset(et_glob, ppe_params, n_test)\n",
    "\n",
    "# train emulator\n",
    "et_em = train_emulator(num_params, params_train, et_train)\n",
    "\n",
    "# predict test points with emulator\n",
    "et_pred, et_pred_var = et_em.predict(params_test)\n",
    "st_dev = et_pred_var.flatten()**0.5\n",
    "rms = mean_squared_error(et_test, et_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd2db3-4468-4cad-8f2e-85eb40515869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'et_test': et_test,\n",
    "      'et_pred': et_pred,\n",
    "      'et_var': et_pred_var}\n",
    "et_test_pred = pd.DataFrame(df)\n",
    "et_test_pred.to_csv('LH_output_global/et_test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f50b3-026f-4d8e-ba97-9bc74751003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ooat_sens(ppe_params, et_em, 'LH_output', 'et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fae64-18de-4d05-9417-9b209b24b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_sens = fourier_sensitivity(et_em)\n",
    "et_sens.to_csv('LH_output_global/et_sensitivity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24369ff3-3e75-4788-a036-850c0017fbe1",
   "metadata": {},
   "source": [
    "## Global Annual Sensible Heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb8d2-4708-4b88-b042-196d8c1ed48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global annual mean (W/m2)\n",
    "h_glob = annual_mean(area_mean(ds, 'FSH', 'global', cfs, land_area)).mean(dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724a6e1-6232-4407-ae4a-4cf3c4fc6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training/testing\n",
    "params_test, params_train, h_test, h_train = split_dataset(h_glob, ppe_params, n_test)\n",
    "\n",
    "# train emulator\n",
    "h_em = train_emulator(num_params, params_train, h_train)\n",
    "\n",
    "# predict test points with emulator\n",
    "h_pred, h_pred_var = h_em.predict(params_test)\n",
    "st_dev = h_pred_var.flatten()**0.5\n",
    "rms = mean_squared_error(h_test, h_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedb59c-2c63-4308-b339-71b034811916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted values\n",
    "plt.scatter(h_test, h_pred)\n",
    "plt.plot([min(h_test), max(h_test)], [min(h_test), max(h_test)], c='k',\n",
    "         linestyle='--', label='1:1 line')\n",
    "plt.errorbar(h_test.flatten(), h_pred.flatten(), yerr=2*st_dev, fmt=\"o\")\n",
    "plt.text(min(h_test), max(h_test), 'RMSE = {}'.format(np.round(rms, 3)))\n",
    "plt.xlabel('FATES global mean annual mean LH (W m$^{-2}$)')\n",
    "plt.ylabel('Emulated global mean annual mean LH (W m$^{-2}$)')\n",
    "plt.legend(loc='lower right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0fbdc-55e8-4b83-8371-77f9db0f53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oaat_sens(ppe_params, h_em, default_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53e230-8d41-4fac-b498-1479cb1be11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sens = fourier_sensitivity(h_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92332dd8-874a-4e7a-817b-40d61c94bbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_analysis]",
   "language": "python",
   "name": "conda-env-ml_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
